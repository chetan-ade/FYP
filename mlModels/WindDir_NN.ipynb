{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WindDir_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3SZRoBPQBpuMbX8UzZQEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetan-ade/FYP/blob/master/WindDir_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5OqjR40OeTF",
        "colab_type": "code",
        "colab": {},
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow_core.python.keras.models import Sequential\n",
        "from tensorflow_core.python.keras.layers import Activation, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow_core.python.keras.utils import np_utils\n",
        "import datetime\n",
        "from datetime import date"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cfeBY22PB_g",
        "colab_type": "code",
        "outputId": "fc4519fe-59c6-4d7e-c8bc-f2b239751313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "location = '21.238611,73.350000'\n",
        "filename = location+\"_preprocessed.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0        date  day  month WindDir  WindspeedKmph\n0           0  2008-07-01    1      7      SW             17\n1           1  2008-07-02    2      7      SW             21\n2           2  2008-07-03    3      7      SW             18\n3           3  2008-07-04    4      7      SW             17\n4           4  2008-07-05    5      7      SW             18",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>day</th>\n      <th>month</th>\n      <th>WindDir</th>\n      <th>WindspeedKmph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2008-07-01</td>\n      <td>1</td>\n      <td>7</td>\n      <td>SW</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2008-07-02</td>\n      <td>2</td>\n      <td>7</td>\n      <td>SW</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2008-07-03</td>\n      <td>3</td>\n      <td>7</td>\n      <td>SW</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2008-07-04</td>\n      <td>4</td>\n      <td>7</td>\n      <td>SW</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2008-07-05</td>\n      <td>5</td>\n      <td>7</td>\n      <td>SW</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6xI1Ua2PMQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(\n",
        "    columns=['day', 'month', 'WindDir']\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhwj95KoQUne",
        "colab_type": "code",
        "outputId": "1ada0d4e-b86e-4264-e29e-09342abd50ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data['day'] = df['day']\n",
        "data['month'] = df['month']\n",
        "data['WindDir'] = df['WindDir']\n",
        "data.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   day  month WindDir\n0    1      7      SW\n1    2      7      SW\n2    3      7      SW\n3    4      7      SW\n4    5      7      SW",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>month</th>\n      <th>WindDir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7</td>\n      <td>SW</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>7</td>\n      <td>SW</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>7</td>\n      <td>SW</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>7</td>\n      <td>SW</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>7</td>\n      <td>SW</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSycMoYVDCFP",
        "colab_type": "code",
        "outputId": "cf5e6c91-a59f-4ed9-dd3d-5513d8238d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "               day        month\ncount  4291.000000  4291.000000\nmean     15.727336     6.556048\nstd       8.799939     3.476235\nmin       1.000000     1.000000\n25%       8.000000     3.000000\n50%      16.000000     7.000000\n75%      23.000000    10.000000\nmax      31.000000    12.000000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4291.000000</td>\n      <td>4291.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>15.727336</td>\n      <td>6.556048</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.799939</td>\n      <td>3.476235</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>16.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>23.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>31.000000</td>\n      <td>12.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJf4E5HCUzI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le_pred = LabelEncoder()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfjBU920U1YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = le_pred.fit_transform(data.WindDir)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YoWV43wVIaW",
        "colab_type": "code",
        "outputId": "393ece40-a608-4312-8b9f-59b4cf519835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y = np_utils.to_categorical(y)\n",
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ks91azoHcWq",
        "colab_type": "code",
        "outputId": "d3919b2c-9d7e-48e6-c67e-c6ae6c456609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y = y.astype('int32')\n",
        "y"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0, 0, 0, ..., 0, 1, 0],\n       [0, 0, 0, ..., 0, 1, 0],\n       [0, 0, 0, ..., 0, 1, 0],\n       ...,\n       [0, 0, 0, ..., 0, 1, 0],\n       [0, 0, 0, ..., 0, 1, 0],\n       [0, 0, 0, ..., 0, 1, 0]])"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb9I5hY2YFyZ",
        "colab_type": "code",
        "outputId": "875467a9-34db-4104-9802-4946e501ef8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(4291, 8)"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1rp7027RMZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# xtrain, xtest, ytrain, ytest = train_test_split(data.iloc[:, :-1], y, test_size=0.25)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYEs6DQ5R9YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozyqbgQsSAfs",
        "colab_type": "code",
        "outputId": "839b4c64-ec9b-4ae7-ceb9-b49341a53dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "model.add(Dense(units=16, input_dim=2, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=8, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:tensorflow:From C:\\Users\\Sahil\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 16)                48        \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                544       \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                2112      \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_4 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_6 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_7 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_8 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_9 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_11 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_12 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_13 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_14 (Dense)             (None, 8)                 264       \n=================================================================\nTotal params: 67,192\nTrainable params: 67,192\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wFrcblnTAjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmp6Ce8kTFMy",
        "colab_type": "code",
        "outputId": "24f59b0d-da61-43c1-f36a-8dac3e432b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "model.fit(data.iloc[:, :-1], y, epochs=200, batch_size=512)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "055\nEpoch 6/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.5786 - acc: 0.5055\nEpoch 7/200\n4291/4291 [==============================] - 0s 75us/sample - loss: 1.5649 - acc: 0.5055\nEpoch 8/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.5453 - acc: 0.5055\nEpoch 9/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.5216 - acc: 0.5055\nEpoch 10/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.4809 - acc: 0.5055\nEpoch 11/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.4511 - acc: 0.5055\nEpoch 12/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.4831 - acc: 0.5055\nEpoch 13/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.4071 - acc: 0.5055\nEpoch 14/200\n4291/4291 [==============================] - 0s 74us/sample - loss: 1.3449 - acc: 0.5192\nEpoch 15/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.3228 - acc: 0.5239\nEpoch 16/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.3194 - acc: 0.5157\nEpoch 17/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.2593 - acc: 0.5313\nEpoch 18/200\n4291/4291 [==============================] - 0s 74us/sample - loss: 1.2436 - acc: 0.5379\nEpoch 19/200\n4291/4291 [==============================] - 0s 97us/sample - loss: 1.2139 - acc: 0.5467\nEpoch 20/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.2156 - acc: 0.5425\nEpoch 21/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.2032 - acc: 0.5449\nEpoch 22/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.2119 - acc: 0.5418\nEpoch 23/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.2055 - acc: 0.5488\nEpoch 24/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1912 - acc: 0.5477\nEpoch 25/200\n4291/4291 [==============================] - 0s 74us/sample - loss: 1.1858 - acc: 0.5486\nEpoch 26/200\n4291/4291 [==============================] - 0s 90us/sample - loss: 1.2046 - acc: 0.5409\nEpoch 27/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1999 - acc: 0.5446\nEpoch 28/200\n4291/4291 [==============================] - 0s 90us/sample - loss: 1.1978 - acc: 0.5428\nEpoch 29/200\n4291/4291 [==============================] - 0s 72us/sample - loss: 1.1975 - acc: 0.5460\nEpoch 30/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.2024 - acc: 0.5374\nEpoch 31/200\n4291/4291 [==============================] - 0s 80us/sample - loss: 1.1791 - acc: 0.5502\nEpoch 32/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1814 - acc: 0.5526\nEpoch 33/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1791 - acc: 0.5502\nEpoch 34/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1843 - acc: 0.5479\nEpoch 35/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1849 - acc: 0.5495\nEpoch 36/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.2082 - acc: 0.5437\nEpoch 37/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.2025 - acc: 0.5397\nEpoch 38/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1917 - acc: 0.5467\nEpoch 39/200\n4291/4291 [==============================] - 0s 99us/sample - loss: 1.2028 - acc: 0.5400\nEpoch 40/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1774 - acc: 0.5484\nEpoch 41/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1752 - acc: 0.5509\nEpoch 42/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1749 - acc: 0.5470\nEpoch 43/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1716 - acc: 0.5481\nEpoch 44/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1641 - acc: 0.5565\nEpoch 45/200\n4291/4291 [==============================] - 0s 72us/sample - loss: 1.1651 - acc: 0.5484\nEpoch 46/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1717 - acc: 0.5470\nEpoch 47/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1802 - acc: 0.5512\nEpoch 48/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1624 - acc: 0.5488\nEpoch 49/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1716 - acc: 0.5416\nEpoch 50/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1721 - acc: 0.5453\nEpoch 51/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1707 - acc: 0.5509\nEpoch 52/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1640 - acc: 0.5530\nEpoch 53/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1659 - acc: 0.5486\nEpoch 54/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1633 - acc: 0.5512\nEpoch 55/200\n4291/4291 [==============================] - 0s 87us/sample - loss: 1.1609 - acc: 0.5514\nEpoch 56/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1601 - acc: 0.5563\nEpoch 57/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1647 - acc: 0.5500\nEpoch 58/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1587 - acc: 0.5558\nEpoch 59/200\n4291/4291 [==============================] - 0s 90us/sample - loss: 1.1635 - acc: 0.5474\nEpoch 60/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1630 - acc: 0.5535\nEpoch 61/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1631 - acc: 0.5512\nEpoch 62/200\n4291/4291 [==============================] - 0s 98us/sample - loss: 1.1789 - acc: 0.5453\nEpoch 63/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1892 - acc: 0.5491\nEpoch 64/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.2045 - acc: 0.5428\nEpoch 65/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.2114 - acc: 0.5358\nEpoch 66/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1713 - acc: 0.5502\nEpoch 67/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1693 - acc: 0.5414\nEpoch 68/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1646 - acc: 0.5502\nEpoch 69/200\n4291/4291 [==============================] - 0s 98us/sample - loss: 1.1655 - acc: 0.5481\nEpoch 70/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1616 - acc: 0.5465\nEpoch 71/200\n4291/4291 [==============================] - 0s 115us/sample - loss: 1.1569 - acc: 0.5533\nEpoch 72/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1607 - acc: 0.5460\nEpoch 73/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1673 - acc: 0.5484\nEpoch 74/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1576 - acc: 0.5484\nEpoch 75/200\n4291/4291 [==============================] - 0s 72us/sample - loss: 1.1586 - acc: 0.5509\nEpoch 76/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1583 - acc: 0.5470\nEpoch 77/200\n4291/4291 [==============================] - 0s 91us/sample - loss: 1.1574 - acc: 0.5516\nEpoch 78/200\n4291/4291 [==============================] - 0s 90us/sample - loss: 1.1547 - acc: 0.5486\nEpoch 79/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1530 - acc: 0.5551\nEpoch 80/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1558 - acc: 0.5523\nEpoch 81/200\n4291/4291 [==============================] - 0s 80us/sample - loss: 1.1616 - acc: 0.5502\nEpoch 82/200\n4291/4291 [==============================] - 0s 94us/sample - loss: 1.1544 - acc: 0.5542\nEpoch 83/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1535 - acc: 0.5537\nEpoch 84/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1537 - acc: 0.5526\nEpoch 85/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1571 - acc: 0.5556\nEpoch 86/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1578 - acc: 0.5540\nEpoch 87/200\n4291/4291 [==============================] - 0s 91us/sample - loss: 1.1574 - acc: 0.5540\nEpoch 88/200\n4291/4291 [==============================] - 0s 90us/sample - loss: 1.1523 - acc: 0.5500\nEpoch 89/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1594 - acc: 0.5507\nEpoch 90/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1652 - acc: 0.5521\nEpoch 91/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1744 - acc: 0.5437\nEpoch 92/200\n4291/4291 [==============================] - 0s 74us/sample - loss: 1.1684 - acc: 0.5430\nEpoch 93/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1532 - acc: 0.5560\nEpoch 94/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1513 - acc: 0.5540\nEpoch 95/200\n4291/4291 [==============================] - 0s 87us/sample - loss: 1.1691 - acc: 0.5481\nEpoch 96/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1636 - acc: 0.5502\nEpoch 97/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1581 - acc: 0.5516\nEpoch 98/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1678 - acc: 0.5495\nEpoch 99/200\n4291/4291 [==============================] - 0s 71us/sample - loss: 1.1668 - acc: 0.5425\nEpoch 100/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1732 - acc: 0.5488\nEpoch 101/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1713 - acc: 0.5495\nEpoch 102/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1568 - acc: 0.5432\nEpoch 103/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1742 - acc: 0.5477\nEpoch 104/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1671 - acc: 0.5449\nEpoch 105/200\n4291/4291 [==============================] - 0s 91us/sample - loss: 1.1523 - acc: 0.5495\nEpoch 106/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1488 - acc: 0.5528\nEpoch 107/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1498 - acc: 0.5491\nEpoch 108/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1718 - acc: 0.5516\nEpoch 109/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1510 - acc: 0.5523\nEpoch 110/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1505 - acc: 0.5512\nEpoch 111/200\n4291/4291 [==============================] - 0s 71us/sample - loss: 1.1478 - acc: 0.5514\nEpoch 112/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1575 - acc: 0.5488\nEpoch 113/200\n4291/4291 [==============================] - 0s 100us/sample - loss: 1.1437 - acc: 0.5521\nEpoch 114/200\n4291/4291 [==============================] - 0s 74us/sample - loss: 1.1430 - acc: 0.5546\nEpoch 115/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1427 - acc: 0.5560\nEpoch 116/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1515 - acc: 0.5540\nEpoch 117/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1537 - acc: 0.5577\nEpoch 118/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1479 - acc: 0.5558\nEpoch 119/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1521 - acc: 0.5533\nEpoch 120/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1606 - acc: 0.5486\nEpoch 121/200\n4291/4291 [==============================] - 0s 101us/sample - loss: 1.1566 - acc: 0.5535\nEpoch 122/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1567 - acc: 0.5507\nEpoch 123/200\n4291/4291 [==============================] - 0s 104us/sample - loss: 1.1534 - acc: 0.5514\nEpoch 124/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1588 - acc: 0.5470\nEpoch 125/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1457 - acc: 0.5570\nEpoch 126/200\n4291/4291 [==============================] - 0s 103us/sample - loss: 1.1420 - acc: 0.5560\nEpoch 127/200\n4291/4291 [==============================] - 0s 96us/sample - loss: 1.1460 - acc: 0.5488\nEpoch 128/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1508 - acc: 0.5509\nEpoch 129/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1458 - acc: 0.5488\nEpoch 130/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1511 - acc: 0.5514\nEpoch 131/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1569 - acc: 0.5556\nEpoch 132/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1503 - acc: 0.5486\nEpoch 133/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1472 - acc: 0.5544\nEpoch 134/200\n4291/4291 [==============================] - 0s 96us/sample - loss: 1.1456 - acc: 0.5533\nEpoch 135/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1464 - acc: 0.5512\nEpoch 136/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1433 - acc: 0.5553\nEpoch 137/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1545 - acc: 0.5509\nEpoch 138/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1840 - acc: 0.5498\nEpoch 139/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1806 - acc: 0.5432\nEpoch 140/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1649 - acc: 0.5486\nEpoch 141/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1557 - acc: 0.5523\nEpoch 142/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1516 - acc: 0.5560\nEpoch 143/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1580 - acc: 0.5509\nEpoch 144/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1475 - acc: 0.5544\nEpoch 145/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1417 - acc: 0.5556\nEpoch 146/200\n4291/4291 [==============================] - 0s 87us/sample - loss: 1.1454 - acc: 0.5488\nEpoch 147/200\n4291/4291 [==============================] - 0s 79us/sample - loss: 1.1416 - acc: 0.5577\nEpoch 148/200\n4291/4291 [==============================] - 0s 75us/sample - loss: 1.1399 - acc: 0.5588\nEpoch 149/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1416 - acc: 0.5507\nEpoch 150/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1457 - acc: 0.5519\nEpoch 151/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1393 - acc: 0.5558\nEpoch 152/200\n4291/4291 [==============================] - 0s 75us/sample - loss: 1.1461 - acc: 0.5544\nEpoch 153/200\n4291/4291 [==============================] - 0s 90us/sample - loss: 1.1513 - acc: 0.5498\nEpoch 154/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1416 - acc: 0.5558\nEpoch 155/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1449 - acc: 0.5551\nEpoch 156/200\n4291/4291 [==============================] - 0s 111us/sample - loss: 1.1451 - acc: 0.5556\nEpoch 157/200\n4291/4291 [==============================] - 0s 71us/sample - loss: 1.1415 - acc: 0.5567\nEpoch 158/200\n4291/4291 [==============================] - 0s 92us/sample - loss: 1.1388 - acc: 0.5570\nEpoch 159/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1394 - acc: 0.5565\nEpoch 160/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1414 - acc: 0.5577\nEpoch 161/200\n4291/4291 [==============================] - 0s 76us/sample - loss: 1.1445 - acc: 0.5546\nEpoch 162/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1482 - acc: 0.5519\nEpoch 163/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1600 - acc: 0.5488\nEpoch 164/200\n4291/4291 [==============================] - 0s 83us/sample - loss: 1.1722 - acc: 0.5451\nEpoch 165/200\n4291/4291 [==============================] - 0s 108us/sample - loss: 1.1576 - acc: 0.5581\nEpoch 166/200\n4291/4291 [==============================] - 0s 99us/sample - loss: 1.1454 - acc: 0.5542\nEpoch 167/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1460 - acc: 0.5488\nEpoch 168/200\n4291/4291 [==============================] - 0s 93us/sample - loss: 1.1422 - acc: 0.5553\nEpoch 169/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1428 - acc: 0.5570\nEpoch 170/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1457 - acc: 0.5484\nEpoch 171/200\n4291/4291 [==============================] - 0s 99us/sample - loss: 1.1483 - acc: 0.5607\nEpoch 172/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1378 - acc: 0.5586\nEpoch 173/200\n4291/4291 [==============================] - 0s 89us/sample - loss: 1.1447 - acc: 0.5560\nEpoch 174/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1472 - acc: 0.5549\nEpoch 175/200\n4291/4291 [==============================] - 0s 85us/sample - loss: 1.1364 - acc: 0.5591\nEpoch 176/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1379 - acc: 0.5567\nEpoch 177/200\n4291/4291 [==============================] - 0s 77us/sample - loss: 1.1385 - acc: 0.5581\nEpoch 178/200\n4291/4291 [==============================] - 0s 96us/sample - loss: 1.1359 - acc: 0.5577\nEpoch 179/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1336 - acc: 0.5595\nEpoch 180/200\n4291/4291 [==============================] - 0s 84us/sample - loss: 1.1323 - acc: 0.5598\nEpoch 181/200\n4291/4291 [==============================] - 0s 82us/sample - loss: 1.1372 - acc: 0.5605\nEpoch 182/200\n4291/4291 [==============================] - 0s 78us/sample - loss: 1.1408 - acc: 0.5519\nEpoch 183/200\n4291/4291 [==============================] - 0s 80us/sample - loss: 1.1483 - acc: 0.5570\nEpoch 184/200\n4291/4291 [==============================] - 0s 94us/sample - loss: 1.1556 - acc: 0.5505\nEpoch 185/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1553 - acc: 0.5540\nEpoch 186/200\n4291/4291 [==============================] - 0s 97us/sample - loss: 1.1509 - acc: 0.5528\nEpoch 187/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1523 - acc: 0.5544\nEpoch 188/200\n4291/4291 [==============================] - 0s 108us/sample - loss: 1.1699 - acc: 0.5521\nEpoch 189/200\n4291/4291 [==============================] - 0s 87us/sample - loss: 1.1729 - acc: 0.5465\nEpoch 190/200\n4291/4291 [==============================] - 0s 91us/sample - loss: 1.1567 - acc: 0.5544\nEpoch 191/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1573 - acc: 0.5567\nEpoch 192/200\n4291/4291 [==============================] - 0s 88us/sample - loss: 1.1428 - acc: 0.5567\nEpoch 193/200\n4291/4291 [==============================] - 0s 99us/sample - loss: 1.1349 - acc: 0.5605\nEpoch 194/200\n4291/4291 [==============================] - 0s 75us/sample - loss: 1.1383 - acc: 0.5584\nEpoch 195/200\n4291/4291 [==============================] - 0s 86us/sample - loss: 1.1450 - acc: 0.5565\nEpoch 196/200\n4291/4291 [==============================] - 0s 87us/sample - loss: 1.1514 - acc: 0.5535\nEpoch 197/200\n4291/4291 [==============================] - 0s 101us/sample - loss: 1.1496 - acc: 0.5530\nEpoch 198/200\n4291/4291 [==============================] - 0s 95us/sample - loss: 1.1447 - acc: 0.5551\nEpoch 199/200\n4291/4291 [==============================] - 0s 80us/sample - loss: 1.1533 - acc: 0.5570\nEpoch 200/200\n4291/4291 [==============================] - 0s 81us/sample - loss: 1.1468 - acc: 0.5523\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1413eb48>"
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl7Sn4K2dvjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_date = df['date'].iloc[-1]\n",
        "last_date = datetime.datetime.strptime(last_date, \"%Y-%m-%d\").date()\n",
        "\n",
        "pred_date = []\n",
        "for i in range(1, 91):\n",
        "    pred_date.append(last_date + datetime.timedelta(days=i))\n",
        "\n",
        "pred_input = [[] for i in range(90)]\n",
        "i = 0\n",
        "for j in pred_date:\n",
        "    pred_input[i].append(j.day)\n",
        "    pred_input[i].append(j.month)\n",
        "    i += 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rxaSz8nvFcb",
        "colab_type": "code",
        "outputId": "c54d18ad-35d2-4795-b191-17a90a1b358a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "sample = pd.DataFrame(\n",
        "    columns=['day', 'month'],\n",
        "    data=pred_input\n",
        ")\n",
        "sample"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "    day  month\n0    31      3\n1     1      4\n2     2      4\n3     3      4\n4     4      4\n..  ...    ...\n85   24      6\n86   25      6\n87   26      6\n88   27      6\n89   28      6\n\n[90 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>24</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>25</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>26</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>27</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>28</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows × 2 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRO0569RyVUt",
        "colab_type": "code",
        "outputId": "8901a588-1192-48ef-f5a3-c2cffc414101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sample_p = model.predict(sample)\n",
        "sample_p"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[3.43493419e-03, 6.85882464e-04, 1.18432892e-02, 1.17378265e-01,\n        1.14566624e-01, 2.09301561e-02, 5.07280171e-01, 2.23880678e-01],\n       [3.62254708e-04, 1.10390545e-04, 2.19456619e-03, 2.65547279e-02,\n        2.80102417e-02, 3.78676760e-03, 6.48921728e-01, 2.90059268e-01],\n       [4.54919718e-05, 3.08840281e-05, 3.23484128e-04, 1.46854771e-02,\n        7.89466407e-03, 6.02091081e-04, 6.99768066e-01, 2.76649892e-01],\n       [2.52072787e-05, 2.16995086e-05, 1.80225048e-04, 1.13711134e-02,\n        5.27213886e-03, 3.66972439e-04, 7.32546449e-01, 2.50216156e-01],\n       [1.55815957e-04, 6.81882302e-05, 1.03796355e-03, 2.01461166e-02,\n        1.62302069e-02, 1.74018077e-03, 6.62466109e-01, 2.98155397e-01],\n       [3.75431497e-04, 1.20589364e-04, 2.30776332e-03, 2.39787549e-02,\n        2.68031377e-02, 3.88382678e-03, 6.46708131e-01, 2.95822352e-01],\n       [1.15123240e-03, 2.28985708e-04, 6.62209000e-03, 2.94831879e-02,\n        5.26154712e-02, 1.13644348e-02, 6.15307212e-01, 2.83227414e-01],\n       [2.00678082e-03, 3.32512485e-04, 1.09747248e-02, 3.51905338e-02,\n        7.48877078e-02, 1.91448256e-02, 5.87941289e-01, 2.69521624e-01],\n       [3.11471336e-03, 4.52856097e-04, 1.59160439e-02, 4.17344011e-02,\n        9.78230312e-02, 2.81871073e-02, 5.57179034e-01, 2.55592823e-01],\n       [4.58245864e-03, 5.86306327e-04, 2.17825994e-02, 4.85896394e-02,\n        1.23505995e-01, 3.92454788e-02, 5.21577895e-01, 2.40129605e-01],\n       [4.83388174e-03, 6.17358135e-04, 2.21889280e-02, 5.28326444e-02,\n        1.26836777e-01, 3.98335718e-02, 5.14985263e-01, 2.37871602e-01],\n       [4.24905773e-03, 5.70845092e-04, 1.91382021e-02, 5.67927770e-02,\n        1.17734283e-01, 3.39527018e-02, 5.25104105e-01, 2.42458060e-01],\n       [3.15165403e-03, 4.97977366e-04, 1.42286411e-02, 6.25166297e-02,\n        1.00459985e-01, 2.45816689e-02, 5.46200871e-01, 2.48362631e-01],\n       [2.09544296e-03, 4.09153232e-04, 9.70410556e-03, 7.01107159e-02,\n        8.19456130e-02, 1.61180645e-02, 5.69531798e-01, 2.50085115e-01],\n       [2.05201702e-03, 4.01344354e-04, 9.29368008e-03, 7.95743167e-02,\n        8.42861831e-02, 1.53883817e-02, 5.66243052e-01, 2.42761046e-01],\n       [2.08929763e-03, 4.02241334e-04, 9.16029327e-03, 8.73594880e-02,\n        8.79851431e-02, 1.52983675e-02, 5.60792565e-01, 2.36912653e-01],\n       [1.82289921e-03, 3.75565694e-04, 7.92803429e-03, 9.24874842e-02,\n        8.29282776e-02, 1.31730409e-02, 5.65753400e-01, 2.35531271e-01],\n       [1.10857910e-03, 2.96727318e-04, 5.05718868e-03, 9.25896615e-02,\n        6.21356554e-02, 8.19086935e-03, 5.89927375e-01, 2.40693972e-01],\n       [6.64982537e-04, 2.34760737e-04, 3.22025362e-03, 9.04428661e-02,\n        4.55240905e-02, 5.09422459e-03, 6.10023081e-01, 2.44795769e-01],\n       [5.34024613e-04, 2.20752248e-04, 2.65241321e-03, 8.92888084e-02,\n        3.88734601e-02, 4.09627240e-03, 6.17133498e-01, 2.47200757e-01],\n       [4.52404434e-04, 2.11275314e-04, 2.30725063e-03, 8.78953412e-02,\n        3.42663266e-02, 3.47262924e-03, 6.22588277e-01, 2.48806581e-01],\n       [4.77979571e-04, 2.17197870e-04, 2.40414869e-03, 9.02781412e-02,\n        3.56734060e-02, 3.63501837e-03, 6.19984031e-01, 2.47330144e-01],\n       [5.46452240e-04, 2.26545439e-04, 2.67429347e-03, 9.39985290e-02,\n        3.96181270e-02, 4.11832472e-03, 6.14420056e-01, 2.44397670e-01],\n       [6.14103861e-04, 2.34416249e-04, 2.93905823e-03, 9.69168097e-02,\n        4.34101075e-02, 4.60432982e-03, 6.09292626e-01, 2.41988540e-01],\n       [6.22897642e-04, 2.31903919e-04, 2.97442568e-03, 9.73509327e-02,\n        4.42442894e-02, 4.68865316e-03, 6.08758211e-01, 2.41128609e-01],\n       [7.61115167e-04, 2.48346361e-04, 3.51535226e-03, 1.00839630e-01,\n        5.11543080e-02, 5.67110535e-03, 5.99978924e-01, 2.37831280e-01],\n       [8.84167617e-04, 2.64934119e-04, 3.99543531e-03, 1.03140943e-01,\n        5.64185344e-02, 6.51052082e-03, 5.93186140e-01, 2.35599384e-01],\n       [9.68230015e-04, 2.83065398e-04, 4.29853750e-03, 1.04879454e-01,\n        5.90851642e-02, 7.00972928e-03, 5.88476419e-01, 2.34999433e-01],\n       [1.04106113e-03, 3.00705549e-04, 4.55164723e-03, 1.06290884e-01,\n        6.10619672e-02, 7.41591863e-03, 5.84571064e-01, 2.34766826e-01],\n       [1.10718654e-03, 3.16956925e-04, 4.77665057e-03, 1.07543260e-01,\n        6.27540499e-02, 7.77483825e-03, 5.81163704e-01, 2.34563425e-01],\n       [1.08544319e-03, 3.22612235e-04, 4.67327749e-03, 1.07867092e-01,\n        6.12213537e-02, 7.55777908e-03, 5.81724167e-01, 2.35548243e-01],\n       [2.16602712e-06, 3.57324598e-06, 6.95174185e-06, 2.95177964e-03,\n        1.37798046e-03, 3.02595763e-05, 9.07935023e-01, 8.76923278e-02],\n       [1.05155380e-06, 8.55714688e-07, 1.30601666e-06, 7.85586191e-04,\n        1.79572601e-03, 1.06885154e-05, 9.51915205e-01, 4.54895347e-02],\n       [1.11430450e-06, 5.48600497e-07, 7.62383706e-07, 3.79072619e-04,\n        2.75613996e-03, 8.79737763e-06, 9.61629212e-01, 3.52244303e-02],\n       [1.15259184e-06, 7.21531535e-07, 1.08010215e-06, 5.43350645e-04,\n        2.27693003e-03, 1.03207813e-05, 9.55268145e-01, 4.18982282e-02],\n       [1.82675251e-06, 2.40939175e-06, 4.85823330e-06, 1.82118884e-03,\n        1.39822089e-03, 2.36705364e-05, 9.19543803e-01, 7.72040337e-02],\n       [4.57538181e-06, 7.62699301e-06, 1.77874554e-05, 4.04235534e-03,\n        1.87088258e-03, 6.92661415e-05, 8.60716820e-01, 1.33270711e-01],\n       [1.65237325e-05, 2.53597773e-05, 8.81801679e-05, 1.01117687e-02,\n        3.34892492e-03, 2.21913797e-04, 7.95029521e-01, 1.91157788e-01],\n       [3.93003429e-05, 5.01714130e-05, 2.18784320e-04, 1.54969832e-02,\n        5.44711575e-03, 4.55920876e-04, 7.54259825e-01, 2.24031836e-01],\n       [4.34281028e-05, 5.76675848e-05, 2.37765751e-04, 1.76264010e-02,\n        5.71099482e-03, 4.85384488e-04, 7.53585398e-01, 2.22252995e-01],\n       [4.61368654e-05, 6.28473426e-05, 2.47781223e-04, 1.98512264e-02,\n        5.99703239e-03, 5.01795032e-04, 7.54373193e-01, 2.18920022e-01],\n       [4.34651738e-05, 6.27295012e-05, 2.28624951e-04, 2.14820243e-02,\n        5.89166675e-03, 4.68387327e-04, 7.61033416e-01, 2.10789680e-01],\n       [3.22399392e-05, 5.30855214e-05, 1.63211123e-04, 2.06952468e-02,\n        4.98943543e-03, 3.55248165e-04, 7.80065715e-01, 1.93645835e-01],\n       [1.89184757e-05, 3.52191637e-05, 8.81616361e-05, 1.62692480e-02,\n        3.62672796e-03, 2.14983200e-04, 8.25502872e-01, 1.54243872e-01],\n       [1.53019155e-05, 2.83216978e-05, 6.21515646e-05, 1.38251986e-02,\n        3.26951197e-03, 1.64528974e-04, 8.58233333e-01, 1.24401689e-01],\n       [2.05731631e-05, 3.69731133e-05, 8.39479035e-05, 1.62894484e-02,\n        3.83114512e-03, 2.08779704e-04, 8.50967884e-01, 1.28561258e-01],\n       [3.36020094e-05, 5.76905950e-05, 1.54426045e-04, 2.31367294e-02,\n        5.01080276e-03, 3.31284828e-04, 8.21388125e-01, 1.49887279e-01],\n       [6.16312755e-05, 9.20763923e-05, 2.95314676e-04, 3.25954892e-02,\n        7.27980770e-03, 5.65001334e-04, 7.86009014e-01, 1.73101738e-01],\n       [1.12271387e-04, 1.43678379e-04, 5.57303836e-04, 4.54013161e-02,\n        1.05504077e-02, 9.51374823e-04, 7.44828820e-01, 1.97454795e-01],\n       [1.39791722e-04, 1.68217055e-04, 6.94982475e-04, 5.09676337e-02,\n        1.20479502e-02, 1.14035176e-03, 7.30514526e-01, 2.04326525e-01],\n       [1.27969572e-04, 1.58422859e-04, 6.25253306e-04, 4.85694297e-02,\n        1.13649247e-02, 1.04546535e-03, 7.43372560e-01, 1.94735929e-01],\n       [1.08958833e-04, 1.40484961e-04, 5.25540498e-04, 4.49219868e-02,\n        1.03078680e-02, 9.03660664e-04, 7.60144055e-01, 1.82947397e-01],\n       [8.98894068e-05, 1.26393788e-04, 3.77712800e-04, 3.63904610e-02,\n        8.82643089e-03, 7.07907951e-04, 7.98355460e-01, 1.55125722e-01],\n       [7.99353220e-05, 1.16231364e-04, 2.77778308e-04, 2.92300545e-02,\n        8.05379543e-03, 5.69147698e-04, 8.31825614e-01, 1.29847437e-01],\n       [7.34159912e-05, 1.07611144e-04, 2.10148573e-04, 2.40685008e-02,\n        7.74501404e-03, 4.89566475e-04, 8.54455352e-01, 1.12850338e-01],\n       [7.04291233e-05, 9.88961328e-05, 1.64904006e-04, 2.05026921e-02,\n        7.99223501e-03, 4.46984515e-04, 8.69327962e-01, 1.01395853e-01],\n       [6.94330301e-05, 9.68549066e-05, 1.59425472e-04, 2.02654004e-02,\n        8.02174769e-03, 4.38376796e-04, 8.71410429e-01, 9.95383114e-02],\n       [6.91948590e-05, 9.99874756e-05, 1.90942024e-04, 2.33382843e-02,\n        7.67855812e-03, 4.58347378e-04, 8.61107945e-01, 1.07056804e-01],\n       [6.91854439e-05, 9.97941097e-05, 2.08106052e-04, 2.52030101e-02,\n        7.67586241e-03, 4.71065956e-04, 8.54639232e-01, 1.11633681e-01],\n       [6.85635314e-05, 9.88014654e-05, 2.13804946e-04, 2.59362739e-02,\n        7.64582120e-03, 4.73200460e-04, 8.52103829e-01, 1.13459602e-01],\n       [6.78110155e-05, 9.76464653e-05, 2.19045120e-04, 2.66462360e-02,\n        7.60793965e-03, 4.74415923e-04, 8.49670887e-01, 1.15215920e-01],\n       [7.02734396e-05, 1.00057456e-04, 2.45035248e-04, 2.90682260e-02,\n        7.80746015e-03, 5.05969510e-04, 8.40575516e-01, 1.21627510e-01],\n       [1.46421189e-05, 9.65924642e-07, 7.56573911e-07, 7.59334507e-05,\n        4.44936380e-02, 2.60911238e-05, 9.40087557e-01, 1.53004378e-02],\n       [7.45305579e-06, 4.18946030e-07, 3.35085531e-07, 4.23370548e-05,\n        3.65370139e-02, 1.42130493e-05, 9.50271070e-01, 1.31271593e-02],\n       [6.23551387e-06, 3.43973937e-07, 2.80633827e-07, 3.70007365e-05,\n        3.40029448e-02, 1.23500513e-05, 9.52778101e-01, 1.31627964e-02],\n       [6.62881439e-06, 3.79298399e-07, 3.14418543e-07, 3.96599389e-05,\n        3.39048207e-02, 1.33469066e-05, 9.52010691e-01, 1.40241506e-02],\n       [9.43595478e-06, 5.97662563e-07, 5.02017258e-07, 5.41733389e-05,\n        3.67591754e-02, 1.88398189e-05, 9.47007358e-01, 1.61499381e-02],\n       [1.48379077e-05, 1.05249580e-06, 8.79032655e-07, 8.02992290e-05,\n        4.16320823e-02, 2.85700371e-05, 9.39984739e-01, 1.82575285e-02],\n       [1.90238025e-05, 1.40356019e-06, 1.17136142e-06, 9.69733301e-05,\n        4.50541489e-02, 3.57059434e-05, 9.35499907e-01, 1.92917250e-02],\n       [2.36134038e-05, 1.80172401e-06, 1.46846980e-06, 1.15618990e-04,\n        4.89487909e-02, 4.25016151e-05, 9.31544423e-01, 1.93217732e-02],\n       [3.02051994e-05, 2.45962974e-06, 1.96287010e-06, 1.45000711e-04,\n        5.29207811e-02, 5.26139847e-05, 9.26908791e-01, 1.99381523e-02],\n       [3.98482880e-05, 3.38894574e-06, 2.68336316e-06, 1.79497889e-04,\n        5.78987226e-02, 6.69880537e-05, 9.20923471e-01, 2.08853427e-02],\n       [5.52676429e-05, 5.01885961e-06, 3.98122529e-06, 2.33122380e-04,\n        6.34914264e-02, 9.03197069e-05, 9.13346291e-01, 2.27746237e-02],\n       [7.29650856e-05, 7.03370324e-06, 5.55831502e-06, 2.93410354e-04,\n        6.86981156e-02, 1.16032257e-04, 9.06520784e-01, 2.42860597e-02],\n       [8.82014720e-05, 8.89691091e-06, 6.99867269e-06, 3.45756882e-04,\n        7.23567605e-02, 1.37567404e-04, 9.01691198e-01, 2.53646486e-02],\n       [1.01350139e-04, 1.11479894e-05, 8.66494065e-06, 4.21657431e-04,\n        7.30143934e-02, 1.58173963e-04, 8.99541080e-01, 2.67435685e-02],\n       [1.13641254e-04, 1.44377964e-05, 1.11748195e-05, 5.49960008e-04,\n        6.97477162e-02, 1.85581928e-04, 8.99895966e-01, 2.94814445e-02],\n       [1.28912463e-04, 1.71792963e-05, 1.32832247e-05, 6.28948677e-04,\n        7.12229908e-02, 2.10222468e-04, 8.96981716e-01, 3.07966601e-02],\n       [1.50320237e-04, 2.04622265e-05, 1.58315524e-05, 7.02247315e-04,\n        7.47793391e-02, 2.40684574e-04, 8.92249465e-01, 3.18417102e-02],\n       [1.78915143e-04, 2.51281217e-05, 1.94814274e-05, 8.02436029e-04,\n        7.85972849e-02, 2.81844230e-04, 8.86826038e-01, 3.32689360e-02],\n       [2.13364605e-04, 3.29372342e-05, 2.54821371e-05, 1.00675260e-03,\n        7.94338360e-02, 3.39802355e-04, 8.83016229e-01, 3.59316170e-02],\n       [2.70819030e-04, 4.77307913e-05, 3.69261543e-05, 1.37343269e-03,\n        8.02257732e-02, 4.39590047e-04, 8.77401531e-01, 4.02041785e-02],\n       [3.35851568e-04, 6.48923597e-05, 5.03613555e-05, 1.74292026e-03,\n        8.23050365e-02, 5.48591895e-04, 8.70998204e-01, 4.39541712e-02],\n       [3.56889330e-04, 7.35879730e-05, 5.72723402e-05, 1.98478438e-03,\n        8.06177408e-02, 5.93799283e-04, 8.70478570e-01, 4.58373018e-02],\n       [3.56367993e-04, 7.80851769e-05, 6.10885545e-05, 2.18798546e-03,\n        7.70492330e-02, 6.08826638e-04, 8.72584879e-01, 4.70734760e-02],\n       [3.59757600e-04, 7.46670848e-05, 5.80177293e-05, 2.01837881e-03,\n        8.05394351e-02, 5.98050363e-04, 8.70474458e-01, 4.58772406e-02],\n       [3.56759963e-04, 6.97593714e-05, 5.42191337e-05, 1.82930962e-03,\n        8.35598782e-02, 5.78883162e-04, 8.68941545e-01, 4.46095578e-02],\n       [3.92706017e-04, 6.99687371e-05, 5.54001017e-05, 1.65653753e-03,\n        9.17101651e-02, 6.05439418e-04, 8.61628890e-01, 4.38808687e-02],\n       [4.36999457e-04, 7.00153323e-05, 5.66076997e-05, 1.47671707e-03,\n        1.01844266e-01, 6.35861419e-04, 8.52479577e-01, 4.29999754e-02],\n       [4.67831618e-04, 7.15750939e-05, 5.87373761e-05, 1.41910138e-03,\n        1.06929906e-01, 6.64853083e-04, 8.47272277e-01, 4.31157313e-02]],\n      dtype=float32)"
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1_qhhwGzBA4",
        "colab_type": "code",
        "outputId": "274047e2-60cb-4aa8-9403-ca9a13c758c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sample_pred = [0 for i in range(len(sample_p))]\n",
        "for i in range(len(sample_p)):\n",
        "    maxm = max(sample_p[i])\n",
        "    for j in range(len(sample_p[i])):\n",
        "        if sample_p[i][j] == maxm:\n",
        "            index = j\n",
        "    sample_pred[i] = index\n",
        "print(sample_pred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCFMLkQhzS-C",
        "colab_type": "code",
        "outputId": "d8de07ed-645a-458c-94da-65a6060fe5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "directions = le_pred.inverse_transform(sample_pred)\n",
        "directions"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW', 'SW',\n       'SW', 'SW'], dtype=object)"
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpUoeGEChINF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3a95bd77-6231-4783-e58a-5a97b29f269d"
      },
      "source": [
        "for i in range(len(directions)):\n",
        "    if directions[i] == 'N':\n",
        "        c = np.random.randint(0, 1)\n",
        "        if c == 0:\n",
        "            directions[i] = np.random.randint(0, 22.5)\n",
        "        elif c == 1:\n",
        "            directions[i] = np.random.randint(337.5, 360)\n",
        "    elif directions[i] == 'NE':\n",
        "        directions[i] = np.random.randint(22.5, 67.5)\n",
        "    elif directions[i] == 'E':\n",
        "        directions[i] = np.random.randint(67.5, 112.5)\n",
        "    elif directions[i] == 'SE':\n",
        "        directions[i] = np.random.randint(112.5, 157.5)\n",
        "    elif directions[i] == 'S':\n",
        "        directions[i] = np.random.randint(157.5, 202.5)\n",
        "    elif directions[i] == 'SW':\n",
        "        directions[i] = np.random.randint(202.5, 247.5)\n",
        "    elif directions[i] == 'W':\n",
        "        directions[i] = np.random.randint(247.5, 292.5)\n",
        "    elif directions[i] == 'NW':\n",
        "        directions[i] = np.random.randint(292.5, 337.5)\n",
        "directions"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([207, 209, 216, 239, 245, 210, 222, 209, 221, 237, 230, 230, 236,\n       211, 233, 209, 210, 218, 208, 236, 210, 223, 222, 208, 210, 219,\n       203, 202, 228, 233, 208, 244, 206, 246, 244, 224, 235, 213, 233,\n       240, 216, 217, 211, 209, 224, 219, 241, 245, 219, 225, 214, 245,\n       215, 222, 209, 243, 228, 246, 202, 242, 211, 208, 224, 238, 231,\n       246, 226, 228, 235, 213, 209, 220, 242, 205, 225, 206, 222, 239,\n       237, 229, 244, 221, 213, 234, 246, 203, 221, 229, 219, 207],\n      dtype=object)"
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_BYgTA5fIoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_data = pd.DataFrame(\n",
        "    columns=['date', 'direction', 'speed']\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVUUYLlJffiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ffdb6749-c3df-41ec-9714-b80db62b1603"
      },
      "source": [
        "pred_data['date'] = pred_date\n",
        "pred_data['direction'] = directions\n",
        "pred_data"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "          date direction speed\n0   2020-03-31       207   NaN\n1   2020-04-01       209   NaN\n2   2020-04-02       216   NaN\n3   2020-04-03       239   NaN\n4   2020-04-04       245   NaN\n..         ...       ...   ...\n85  2020-06-24       203   NaN\n86  2020-06-25       221   NaN\n87  2020-06-26       229   NaN\n88  2020-06-27       219   NaN\n89  2020-06-28       207   NaN\n\n[90 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>direction</th>\n      <th>speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-03-31</td>\n      <td>207</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-04-01</td>\n      <td>209</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-04-02</td>\n      <td>216</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-04-03</td>\n      <td>239</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-04-04</td>\n      <td>245</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>2020-06-24</td>\n      <td>203</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>2020-06-25</td>\n      <td>221</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-06-26</td>\n      <td>229</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-06-27</td>\n      <td>219</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-06-28</td>\n      <td>207</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows × 3 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nijZVRA6g3NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = location+\".csv\"\n",
        "pred_data.to_csv(filename, mode='a', header=False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk1K9rTrImAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}